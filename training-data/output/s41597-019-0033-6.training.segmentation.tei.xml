<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<front>1 <lb/>Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/>www.nature.com/scientificdata <lb/>a dataset of publication records for <lb/>Nobel laureates <lb/>Jichao Li 1,2,3 , Yian Yin 2,4 , Santo Fortunato 5,6 &amp; Dashun Wang 2,3,4 <lb/>a central question in the science of science concerns how to develop a quantitative understanding of <lb/>the evolution and impact of individual careers. Over the course of history, a relatively small fraction of <lb/>individuals have made disproportionate, profound, and lasting impacts on science and society. Despite <lb/>a long-standing interest in the careers of scientific elites across diverse disciplines, it remains difficult <lb/>to collect large-scale career histories that could serve as training sets for systematic empirical and <lb/>theoretical studies. Here, by combining unstructured data collected from CVs, university websites, <lb/>and Wikipedia, together with the publication and citation database from Microsoft Academic Graph <lb/>(MAG), we reconstructed publication histories of nearly all Nobel prize winners from the past century, <lb/>through both manual curation and algorithmic disambiguation procedures. Data validation shows that <lb/>the collected dataset presents among the most comprehensive collection of publication records for <lb/>Nobel laureates currently available. As our quantitative understanding of science deepens, this dataset <lb/>is expected to have increasing value. It will not only allow us to quantitatively probe novel patterns <lb/>of productivity, collaboration, and impact governing successful scientific careers, it may also help us <lb/>unearth the fundamental principles underlying creativity and the genesis of scientific breakthroughs. <lb/></front>

			<body>Background &amp; Summary <lb/>Recent advances in the science of science have revealed a series of highly reproducible patterns governing the <lb/>fundamental dynamic of science 1-3 , ranging from citation impact of papers 4-9 , career dynamics 10-22 , to teams <lb/>and collaborations 23-27 . Although scientific elites have attracted ensuing interest from a wide range of discipli <lb/>nes 17,19-22,27-38 , spanning across sociology, economics, psychology, and physics, most quantitative analyses have <lb/>focused on the prize-winning work alone, exploring the link between age and creativity 19,20 , and allocation of <lb/>credits and recognition 27,30,32 . On the other hand, the rich patterns unveiled in qualitative studies 17,29 , including <lb/>Zuckerman&apos;s canonical work, vividly illustrates that the careers of scientific elites encompass projects well beyond <lb/>their prize-winning work. Career-level analyses of these scientific elites have remained elusive, largely due to the <lb/>difficulty in obtaining large-scale, high-resolution individual career histories. <lb/>Many studies have been devoted to building open-access datasets on scientific productivity and careers of <lb/>scientists. For example, Vuong et al. 39 introduced an open database on scientific output of Vietnamese researchers <lb/>in social sciences and humanities; and Morrison et al. 40 developed a name disambiguation method for inventors <lb/>and assignees on 8.47 million patents. While these open-accessed datasets are mostly about ordinary scientists, <lb/>researchers have also been interested in Nobel laureates. For example, Jones et al. 19 collected a biographical data-<lb/>set of 525 Nobel Prize winners, and Fortunato et al. 30 curated data on dates of birth, the year of Nobel prizes and <lb/>year(s) of publication(s) of prize-winning work. Chan et al. 41 collected a dataset consisting of 34,448 publications <lb/>of 192 Nobel laureates between 1970 and 2000 based on the Scopus dataset. Li et al. 42 collected a fraction of papers <lb/>published by Nobel laureates during the period of 1901-2012 using the Web of Science data. These efforts are <lb/>highly complementary to the dataset presented here, highlighting the wide interest in the quantitative study of <lb/>Nobel laureates. <lb/>There have also been practical utilities for such datasets. For example, Clarivate Analytics has developed tools <lb/>that use similar proprietary publication and citation databases to predict future Nobel laureates. While the focus <lb/>of Clarivate Analytics&apos; work is on predicting future laureates, the goal of our paper is to collect a comprehensive <lb/></body>

			<front>1 college of Systems engineering, national University of Defense technology, changsha, china. 2 northwestern <lb/>institute on complex Systems, northwestern University, evanston, iL, USA. 3 Kellogg School of Management, <lb/>northwestern University, evanston, iL, USA. 4 Mccormick School of engineering, northwestern University, evanston, <lb/>iL, USA. 5 School of informatics, computing, and engineering, indiana University, Bloomington, in, USA. 6 indiana <lb/>University network Science institute (iUni), indiana University, Bloomington, in, USA. correspondence and requests <lb/>for materials should be addressed to D.W. (email: dashun.wang@northwestern.edu) <lb/>Received: 6 December 2018 <lb/>Accepted: 7 March 2019 <lb/>Published: xx xx xxxx <lb/>DAtA DeSCriptOr <lb/>OpeN <lb/></front>

			<page>2 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>dataset capturing careers of individual Nobel laureates over the past century, which could then serve as an empir-<lb/>ical starting point for future quantitative studies. <lb/>Here we build an open-access dataset on the scientific careers of Nobel laureates 43 . Despite a plethora of data <lb/>capturing the various contributions of scientific elites, such information is often located in unstructured, isolated <lb/>sources. Here, by combining unstructured information collected from Nobel Prize official websites, laureates&apos; <lb/>personal and university websites, Wikipedia entries, and publication and citation records from the MAG, we con-<lb/>structed a unique dataset of career histories for nearly all Nobel laureates in Physics, Chemistry, and Physiology or <lb/>Medicine from 1900 to 2016 (545 out of 590, 92.4%). We validated this dataset using four different approaches to <lb/>ensure the reliability of our results, including comparison with manually collected CVs, selected Google Scholar <lb/>(GS) profiles, additional affiliation information, and random selection of 60 Nobel laureates (20 for each field) for <lb/>manual verification. The total data collection and validation procedure took more than 1000 hours. <lb/>The curated data could serve as critical input that feeds into several promising research directions. (1) The data <lb/>make available quantitative patterns of productivity, collaboration, and impact governing the careers of scientific <lb/>elites, offering a unique opportunity to systematically identify quantitative signals tracing the careers of elite sci-<lb/>entists. (2) Combining our datasets with publication records that capture the careers of ordinary scientists offers <lb/>opportunities for an array of fascinating comparative studies. Such studies would deepen our understanding <lb/>of the factors driving exceptional scientific careers, helping us answer the broad question of what makes great <lb/>scientists great. <lb/>As a more concrete example, we present two new findings using the curated dataset in the associated commen-<lb/>tary 44 . Briefly, we find that careers of Nobel laureates are characterized by remarkably similar patterns as those of <lb/>ordinary scientists. For example, apart from the prize-winning paper, all other important works in Nobel careers <lb/>closely follow the random impact rule 10,11 , a finding that is contrary to the common belief that Nobel laureates <lb/>tend to do critical work early in their careers. Further, the laureates also show a tendency toward collaborative <lb/>research in larger teams, which runs counter to the iconic image of lone geniuses making solo contributions. <lb/>These results only represent some initial examples of how such datasets can help advance our quantitative <lb/>understanding of career dynamics. Indeed, our dataset may help uncover a set of reproducible principles under-<lb/>lying individual creativity, offering insights into the conditions and environments that best facilitate scientific <lb/>creativity and the genesis of scientific breakthroughs. <lb/>Methods <lb/>We constructed the publication records for almost all Nobel laureates in physics, chemistry, and physiology or <lb/>medicine from 1900 to 2016 (545 out of 590, 92.4%). We first collected information manually from Nobel Prize <lb/>official websites, their university websites, and Wikipedia. We then matched it algorithmically with big data, trac-<lb/>ing publication records from the MAG database. Figure 1 shows the data collection framework. Next, we describe <lb/>how we collected and reconstructed the data we used in the project. <lb/>MAG dataset. The MAG data contains scientific publication records, interlinked through the citation rela-<lb/>tionships between them, together with information about authors, institutions, publication venues (e.g. journals <lb/>or conferences), and fields of study 45 . The dataset is updated on a weekly basis and contains 174,910,379 papers, <lb/>210,983,748 authors, 228,843 fields of study, 4,028 conferences, 47,963 journals, and 25,558 institutions as of June <lb/>2018. <lb/>the biographical website for Nobel laureates. One advantage of studying Nobel laureates is that there <lb/>is a large amount of information available and it is well-maintained by different organizations. Here we make use <lb/>of three important sources: the Nobel Foundation&apos;s website, Wikipedia webpages for the laureates, and university <lb/>websites for the laureates. <lb/>MAG database <lb/>Prize-winning papers <lb/>Other ground truth papers <lb/>Collected publication records <lb/>Multiple sources <lb/>Verification <lb/>} <lb/>{ <lb/>WIKIPEDIA <lb/>Home Page <lb/>nobelprize.org <lb/>Google Scholar <lb/>Affiliation <lb/>Fig. 1 Data collection and validation framework. We first manually collected each laureate&apos;s prize-winning <lb/>paper and other &quot;ground-truth&quot; papers from multiple sources such as Nobel Prize official websites, Wikipedia, <lb/>and their home pages, and matched these papers in MAG database as seeds. The entire publication record for <lb/>each laureate is then collected through a &quot;Seed + Expand&quot; process. The red plus symbols indicate the laureate&apos;s <lb/>papers while the red minus symbols represent noise papers. The obtained dataset is validated with external <lb/>sources, including CVs, GS profiles, affiliation information, and manual verifications. <lb/></body>

			<page>3 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>(1) The Nobel Foundation&apos;s website. The Nobel Foundation&apos;s website (nobelprize.org) offers a rich source of <lb/>information about Nobel laureates. It contains numerous site-accessible documents, photos, audiotapes, <lb/>videotapes, films, and articles for each laureate. <lb/>(2) Wikipedia pages. Wikipedia is a multilingual, web-based, free encyclopedia based on a model of openly <lb/>editable and viewable content (https://www.wikipedia.org/). All Nobel laureates have dedicated pages <lb/>which offer detailed biographical information including biographies, scientific activities, selected publica-<lb/>tion records, awards, and honors, etc. <lb/>(3) University websites for Nobel laureates. Nobel laureates&apos; personal homepages or lab websites offer an <lb/>official account of their career records. These websites usually highlight several selected publications by <lb/>the Nobel laureates, and sometimes even include an expanded list of all publications and official CVs. <lb/>Although university websites are not guaranteed to be up-to-date, the information listed on these websites <lb/>is, in general, highly accurate. <lb/>identifying prize-winning papers. The availability of information about Nobel laureates creates an <lb/>unprecedented opportunity to identify laureates&apos; prize-winning work and to systematically collect their publica-<lb/>tion records throughout their careers. For each Nobel laureate, we collected data on the timing of prize-winning <lb/>work, prize motivation, the title and year of the Nobel lecture, and the author and institution information on <lb/>prize-winning work if it was available. <lb/>The Nobel lecture provides detailed information about the prize-winning work. As such, the prize-winning <lb/>papers are usually cited as references to the Nobel lecture. We collected all the references of Nobel lectures and <lb/>manually collected the prize-winning papers identified in each Nobel lecture. For those that were not mentioned <lb/>specifically in these lectures, we classify the reference of the Nobel lecture as a prize-winning paper if it satisfies all <lb/>of the following criteria: (1) The Nobel laureate is in the author list of the reference paper, i.e., the paper has at least <lb/>one author with the same last name and first name (or first initial if the full first name is missing) with the Nobel <lb/>winner. For an author with a middle name or middle initial, such information must be consistent as well; (2) The <lb/>paper was published within the same period of prize-winning papers; (3) Institution and co-author information <lb/>of the reference is consistent with other auxiliary information about the prize-winning work; (4) The topic of the <lb/>reference paper is consistent with the Nobel Prize motivation. If there are multiple papers that satisfy the criteria <lb/>(1-4), we assume that prize-winning papers garner higher impact (measured by total citation). Following these <lb/>procedures, we manually identified and collected the prize-winning papers for all laureates in our sample (Fig. 2). <lb/>In rare cases where prize-winning papers cannot be reliably identified from the references of the Nobel lec-<lb/>tures, we consulted other sources: (1) Nobel laureates&apos; Wikipedia page usually offers a detailed personal biog-<lb/>raphy, which contains their prize-winning contributions and mentions of prize-winning papers. (2) Important <lb/>works are usually selected by the Nobel laureates and displayed on their personal homepage or lab website, which <lb/>can help us to identify the prize-winning papers. (3) Existing studies have collected some of the prize-winning <lb/>papers. For example, Shen and Barabasi 27 collected the prize-winning papers for Nobel laureates in Physics <lb/>(1995-2013), Chemistry (1998-2013), Medicine (2006-2013), and Economics (1995-2013). Our data collection <lb/>also takes into account these existing efforts. <lb/>We matched all prize-winning papers with the MAG database. Together, we gathered 874 prize-winning <lb/>papers for 545 Nobel laureates, including 283 prize-winning papers for 193 laureates in Physics, 259 prize-winning <lb/>papers for 163 laureates in Chemistry, and 332 prize-winning papers for 189 laureates in Medicine. <lb/>Name disambiguation procedure. A key challenge in analyzing scholarly databases is to identify the <lb/>individual(s) who wrote a paper and, conversely, to identify all of the works that belong to a given individual 46-48 . <lb/>This seemingly simple task represents a major unsolved problem for information and computer sciences, and a <lb/>major roadblock to studies of individual careers. Here we exploit one important feature of the MAG data. Indeed, <lb/>one major advantage of the MAG dataset is that author profiles have been processed through a well-designed dis-<lb/>ambiguation algorithm that optimizes the accuracy of a profile 45,48,49 . That is, each disambiguated profile in MAG <lb/>may not contain all the papers published by an individual, but papers that are included in the profile do belong to <lb/>the same person with high accuracy. In other words, MAG may split one scientist&apos;s publication record into sev-<lb/>eral different profiles, optimizing accuracy at the expense of recall. Note that authors themselves can also claim <lb/>and assemble different profiles into one (https://www.microsoft.com/en-us/research/project/academic/articles/ <lb/>microsoft-academic-uses-knowledge-address-problem-conflation-disambiguation/), offering additional crowd <lb/>intelligence to assist in the disambiguation procedure. This also suggests that if we could intelligently combine <lb/>these profiles, we may be able to curate individual profiles with both high precision and recall. <lb/>In this paper, we adopt a &quot;Seed + Expand&quot; procedure 50 , a method similar to label propagation in machine <lb/>learning 51 to merge various MAG author profiles into one. Figure 3 shows the detailed steps of the name disam-<lb/>biguation procedure, introduced as follows: <lb/>(1) Manually collecting laureates&apos; papers. As part of identifying prize-winning papers, we have collected and <lb/>identified several of the laureates&apos; papers, including the prize-winning papers, Nobel lecture papers, and <lb/>other papers collected from their Wikipedia page, the Nobel official website, and their own homepage. <lb/>These manually collected laureates&apos; papers are referred to as ground-truth papers. <lb/>(2) Matching laureates&apos; papers into the MAG dataset as seeds. We then match these collected laureates&apos; papers <lb/>into the MAG dataset using the following rules: Two papers are identical if they share the same Digital <lb/>Object Identifier (DOI). In cases where the DOI is missing, they are considered to be the same paper if <lb/>the following matching rules are satisfied: (1) the two papers were published within ±1 years; (2) the two <lb/>papers have the same number of authors; (3) author sequence of the two papers is the same; (4) the text <lb/></body>

			<page>4 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>similarity, defined as the cosine similarity between the titles of the paper after removing stop words and <lb/>punctuation, is higher than 0.75. <lb/>(3) Creating a pool of all candidate MAG profiles for each laureate. We then created a pool of all candidate MAG <lb/>profiles for each laureate according to the same rules followed by the literature 11 : (1) the author&apos;s last name <lb/>is identical to the laureate&apos;s last name; (2) initial of the first name is identical to the laureate&apos;s first initial. If an <lb/>author&apos;s full first name is available, it must be the same as the laureate&apos;s; (3) for those authors who have middle <lb/>names, the middle initial must be the same as the laureate&apos;s. If the author&apos;s full middle name is available, it also <lb/>must be consistent with the laureate&apos;s middle name. (4) For each laureate, all the publication records under the <lb/>potential MAG author&apos;s profiles constitute the candidate pool of papers for the laureate. <lb/>(4) Building a citation network within the candidate paper pool through the &quot;Seed + Expand&quot; process. One as-<lb/>sumption for the &quot;Seed + Expand&quot; process is that scientists are more likely to cite their own published work <lb/>due to topical relevance or intellectual similarity between the papers. Thus, their own papers are usually <lb/>connected through a citation network. Starting with the seed papers, we take candidate papers that have <lb/>cited at least one of the seed papers and expand the pool of seeds iteratively. The process stops when there <lb/>are no papers left in the candidate paper pool to be added to the network (Fig. 4). <lb/>Author information of prize-winning achievement <lb/>Step 1: <lb/>Step 2: <lb/>Year of prize-winning achievement <lb/>Step 3: <lb/>Matched Nobel lecture <lb/>paper in MAG dataset <lb/>Prize-winning paper <lb/>Prize motivation <lb/>Title of Nobel Lecture <lb/>Fig. 2 Procedure for identifying the prize-winning paper of 2010 Physics Nobel laureate Andre Geim. Step 1: <lb/>The official website of the Nobel Prize, nobelprize.org, offers rich information for identifying the prize-winning <lb/>works of Nobel laureates, including the year or period of the prize-winning achievement, the prize motivation, <lb/>the title of the Nobel Lecture, etc. Step 2: We can obtain detailed information on the Nobel Lecture in the <lb/>MAG dataset. Step 3: We can identify the prize-winning paper from the reference of the Nobel Lecture using <lb/>information derived in Step 1. <lb/></body>

			<page>5 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>(5) Merging candidate MAG author profiles. For each Nobel laureate, we have a pool of candidate MAG au-<lb/>thors. We then merge all the candidate MAG author profiles that have at least one paper in the citation net-<lb/>work. Combining the merged MAG author&apos;s profiles yields the entire publication history for each laureate. <lb/>Together, we curated publication records for each Nobel laureate, totaling 93,394 journal papers for 545 Nobel <lb/>laureates. <lb/>reliability validation of the manually collected ground-truth papers. The manually collected <lb/>ground-truth papers play an important role in the name disambiguation procedure. These ground-truth papers <lb/>are matched into the MAG dataset as seeds, which are the starting point of the &quot;Seed + Expand&quot; process. Here <lb/>we conducted cross-validation with additional information such as co-authors, affiliations, timing, a paper&apos;s key-<lb/>words, and even e-mail information, if available, to double check each manually collected laureates&apos; paper. We did <lb/>a lot of tinkering to ensure the accuracy and correctness of the collected papers, trying to minimize the human <lb/>errors accounted for in the &quot;Seed + Expand&quot; procedure. Nevertheless, although all these steps help reduce any <lb/>potential human errors in the data curation process, thereby ensuring the accuracy of the collected data, readers <lb/>should take note of the possibility that there may still be errors that remain unaccounted for given the manual <lb/>processes. <lb/>Data records <lb/>Data structure. We built an open-access dataset on publication records for Nobel laureates in Physics, <lb/>Chemistry, and Medicine, which is available at Harvard Dataverse 43 . It contains four comma-separated values <lb/>(CSV) files named &quot;Prize-winning paper record, &quot; &quot;Physics publication record, &quot; <lb/>&quot;Chemistry publication record,&quot; and &quot;Medicine publication record.&quot; The details are further described in <lb/>Table 1. <lb/>&quot;Prize-winning paper record&quot; contains information about prize-winning papers, including &quot;Field, &quot; &quot;Laureate <lb/>ID, &quot; &quot;Laureate name, &quot; &quot;Prize year, &quot; &quot;Title, &quot; &quot;Pub year, &quot; &quot;Paper ID, &quot; and &quot;Additional information&quot; (Table 2). &quot;Field&quot; <lb/>refers to the Nobel laureate&apos;s field, i.e., Physics, Chemistry, or Medicine. We assign a unique &quot;Laureate ID&quot; for each <lb/>laureate, and his/her name and prize-winning year are referred to as &quot;Laureate name&quot; and &quot;Prize year. &quot; &quot;Title&quot; <lb/>and &quot;Pub year&quot; refers to the paper title and publication year of the prize-winning paper. &quot;Paper ID&quot; refers to <lb/>Step 1: Manually collecting laureates&apos; papers <lb/>Step 2: Matching laureates&apos; papers into the MAG dataset as seeds (automatic algorithm) <lb/>Step 4: Building a citation network within the candidate paper pool through &quot;Seed+Expand&quot; <lb/>process (automatic algorithm) <lb/>Step 5: Merging candidate MAG author profiles (automatic algorithm) <lb/>Reliability validataion <lb/>Curated dataset <lb/>validatation with <lb/>manually collected <lb/>CVs <lb/>validate with selected <lb/>GS profiles <lb/>(automatic algorithm) <lb/>validate with additional <lb/>affiliation information <lb/>(automatic algorithm) <lb/>Manually checkup <lb/>Name disambiguation procedure <lb/>Step 3: Creating a pool of all candidate MAG profiles for each laureate (automatic algorithm) <lb/>Fig. 3 Name disambiguation procedure and reliability validation. We curated the Nobel laureates&apos; publication <lb/>records through a name disambiguation procedure. The procedure consists of five steps: first, we manually <lb/>collect laureates&apos; papers; next, the collected laureates&apos; papers are matched into the MAG dataset as seeds; we <lb/>then create a pool of all candidate MAG profiles for each laureate through certain name matching rules; we <lb/>build a citation network within the candidate paper pool through the &quot;Seed + Expand&quot; process; finally, all <lb/>the candidate MAG author profiles are merged to obtain the curated publication record for each laureate. <lb/>The reliability of the curated dataset is verified through four different approaches, including comparison with <lb/>manually collected CVs, selected Google Scholar (GS) profiles, additional affiliation information, and random <lb/>selection of 60 Nobel laureates (20 for each field) for manual verification. <lb/></body>

			<page>6 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>the unique paper ID of each prize-winning paper in the MAG dataset. &quot;Additional information&quot; captures addi-<lb/>tional information about the prize-winning paper that may be relevant for interested readers. For example, John <lb/>Macleod won the Nobel Prize in Physiology or Medicine in 1923 jointly with Frederick G. Banting for the discov-<lb/>ery of insulin (https://www.nobelprize.org/prizes/medicine/1923/macleod/facts/); the experiment that resulted in <lb/>the discovery was mainly conducted by Frederick Banting and Charles Best in John MacLeod&apos;s laboratory in 1921 <lb/>and was first published in the February 1922 issue of The Journal of Laboratory and Clinical Medicine under the <lb/>names Frederick Banting and Charles Best; Macleod declined co-authorship because he considered it Banting&apos;s <lb/>and Best&apos;s work (https://en.wikipedia.org/wiki/John_Macleod_(physiologist)). <lb/>The three files named &quot;Physics publication record, &quot; &quot;Chemistry publication record, &quot; and &quot;Medicine publication <lb/>record&quot; contain the publication records of Nobel laureates for Physics, Chemistry, and Medicine, respectively. <lb/>Each file includes the following data fields (Table 3): &quot;Laureate ID, &quot; &quot;Laureate name, &quot; &quot;Prize year, &quot; &quot;Title, &quot; &quot;Pub <lb/>year, &quot; &quot;Paper ID, &quot; &quot;DOI, &quot; &quot;Journal, &quot; &quot;Affiliation, &quot; and &quot;Is prize-winning paper. &quot; Each data field is self-explanatory <lb/>by its name, and fields with the same name as other tables follow the same data and can be linked across <lb/>tables. &quot;DOI&quot; and &quot;Journal&quot; refer to the DOI and the published journal for each collected paper. &quot;Affiliation&quot; refers <lb/>to the Nobel laureate&apos;s affiliation while publishing the paper. &quot;Is prize-winning paper&quot; shows whether the paper is <lb/>prize-winning or not. If the paper is a prize-winning paper, the value of the item &quot;Is prize-winning paper&quot; is set <lb/>as &quot;YES, &quot; otherwise it is set as &quot;NO. &quot; <lb/>Descriptive statistics. Table 4 shows the descriptive statistics resulting from the datasets in terms of differ-<lb/>ent disciplines. We find that laureates&apos; productivity varies across different disciplines. The Chemistry laureates are <lb/>MAG database <lb/>papers <lb/>a <lb/>b <lb/>Author profile in MAG dataset <lb/>with the same name of Nobel laureates <lb/>noise profile <lb/>Identified ground truth papers <lb/>from multiple sources as seed papers <lb/>Fig. 4 The name disambiguation process for Nobel laureates. (a) We first collected as many ground-truth <lb/>papers as possible from multiple sources, including the Nobel Foundation&apos;s website, Wikipedia&apos;s website for <lb/>Nobel laureates, and the laureate&apos;s homepage. Then the ground-truth papers are matched into the MAG dataset <lb/>as seed papers (red plus symbols). (b) A pool of all candidate MAG author&apos;s profiles for each laureate are <lb/>collected via name matching. Plus symbols indicate the laureate&apos;s papers, and the red pluses denote the collected <lb/>seed papers while the blue ones represent other potential papers by the laureate. The yellow minus symbol <lb/>represents noise papers. (c) Name disambiguation process of the &quot;Seed + Expand&quot; algorithm. Starting with <lb/>the original seed papers, we take candidate papers that have cited at least one of the seed papers as new seeds <lb/>iteratively. The process stops when there is no paper in the pool to be added. We then merge all the candidate <lb/>MAG author&apos;s profiles having at least one paper in the ego citation network. <lb/>File <lb/>Lines <lb/>Short description <lb/>Prize-winning paper record <lb/>873 <lb/>CSV format file containing prize-winning paper items for 545 Nobel laureates <lb/>Physics publication record <lb/>21504 <lb/>CSV format file containing publication items for 193 Physics Nobel laureates <lb/>Chemistry publication record 42657 <lb/>CSV format file containing publication items for 163 Chemistry Nobel laureates <lb/>Medicine publication record <lb/>29233 <lb/>CSV format file containing publication items for 189 Medicine Nobel laureates <lb/>Table 1. Dataset dimensions. <lb/></body>

			<page>7 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>the most productive, with each person publishing an average of 262 papers over their entire career, which is more <lb/>than twice that of the Physics laureates&apos; average. We also find the mean age at which Nobel laureates did their <lb/>prize-winning work is around 40, with no major age differences across disciplines. However, recognition for the <lb/>prize-winning work always takes a long time, with Nobel laureates waiting an average of 17 years to win the Prize <lb/>after making their prize-winning work. <lb/>technical Validation <lb/>reliability validation. To understand the reliability of the curated dataset, we take the following four differ-<lb/>ent approaches to validate the data. <lb/>Validation with CVs of the laureates. We manually collected 30 laureates&apos; CVs from their personal websites, lab <lb/>homepages, or university homepages which contain their full list of publications. Compared against these publi-<lb/>cation histories as the gold standard, our data shows a high precision and recall at 82.3% and 92.2% respectively. <lb/>Validation with GS profiles. Google provides scholar profiles for scientists to create, maintain and update their own <lb/>publication records. Armed with Google&apos;s proprietary name disambiguation algorithms, Google Scholar profiles may <lb/>represent a comprehensive collection of individual publication histories. Keep in mind, however, that GS profiles tend <lb/>to cover currently active scientists, and only a modest fraction of Nobel laureates have their own GS profiles. We col-<lb/>lected GS publication records for 29 Nobel laureates. Since GS indexes not only journal publications but also confer-<lb/>ences, patents, reports, meeting abstracts, talks, reviews, and even slides, here we consider only journal publications. <lb/>Compared against the 29 GS profiles, our data shows precision and recall of 87.2% and 84.2% respectively. <lb/>Index <lb/>Format <lb/>Short description <lb/>Field <lb/>String <lb/>Nobel field for each laureate, i.e., Physics, Chemistry, or Medicine <lb/>Laureate ID <lb/>Integer <lb/>Unique ID for each Laureate <lb/>Laureate name <lb/>String <lb/>Name of the Nobel Laureate <lb/>Prize year <lb/>Integer <lb/>Year when the Laureate won Nobel Prize <lb/>Title <lb/>String <lb/>Title of the prize-winning paper <lb/>Pub year <lb/>Integer <lb/>Publication year of the prize-winning paper <lb/>Paper ID <lb/>Integer <lb/>Unique ID for each prize-winning paper <lb/>Additional information String <lb/>Additional information refers to the prize-winning paper <lb/>Table 2. The data type for the prize-winning paper records. <lb/>Index <lb/>Format <lb/>Short description <lb/>Laureate ID <lb/>Integer <lb/>Unique ID for each Laureate <lb/>Laureate name <lb/>String <lb/>Name of the Nobel Laureate <lb/>Prize year <lb/>Integer <lb/>Year when the Laureate won Nobel Prize <lb/>Title <lb/>String <lb/>Title of the paper <lb/>Pub year <lb/>Integer <lb/>Publication year of the paper <lb/>Paper ID <lb/>Integer <lb/>Unique MAG ID for each paper <lb/>DOI <lb/>String <lb/>Digital Object Identifier (DOI) of the paper <lb/>Journal <lb/>String <lb/>Published journal of the paper <lb/>Affiliation <lb/>String <lb/>Nobel Laureate&apos;s affiliation when publishing the paper <lb/>Is prize-winning paper String <lb/>Whether the paper is a prize-winning paper or not <lb/>Table 3. The data type for publication records of Nobel laureates for Physics, Chemistry, and Medicine. <lb/>Statistics <lb/>Disciplines <lb/>Physics <lb/>Chemistry <lb/>Medicine <lb/>Collected laureates number <lb/>193 <lb/>163 <lb/>189 <lb/>Average publications number <lb/>111 <lb/>262 <lb/>155 <lb/>Average prize-winning paper number <lb/>1.5 <lb/>1.6 <lb/>1.8 <lb/>Average age when making prize-winning papers <lb/>37.9 <lb/>41.0 <lb/>41.6 <lb/>Average age when winning the Nobel Prize <lb/>55.6 <lb/>58.4 <lb/>57.9 <lb/>Average recognition time after making the prize-winning work 17.7 <lb/>17.4 <lb/>16.3 <lb/>Table 4. The descriptive statistics resulted from the datasets. <lb/></body>

			<page>8 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>Validation with additional affiliation information. More than 80% of publications we collected contain author <lb/>affiliations, allowing us to use additional affiliation information to verify the reliability of our data. For each Nobel <lb/>laureate, we first collected his/her affiliations from his/her Wikipedia and University homepage. Then we went <lb/>through the curated publication list to check if the affiliation information recorded in the paper was consistent <lb/>with the laureate&apos;s career history. We find our data has high accuracy (97.6%). <lb/>Manual checkup. The MAG matched the biography information for a selected fraction of Nobel laureates from the <lb/>Wikipedia to the author profiles. We can access this information from the MAG API (https://academic.microsoft.com/). <lb/>We randomly selected 60 Nobel laureates (20 for each field) to manually check the reliability of our data. <lb/>In Fig. 5, we illustrate this process through the example of David Baltimore, an American biologist who won <lb/>the Nobel Prize in Physiology or Medicine in 1975. We identified and merged 24 MAG author profiles with <lb/>the same name (David Baltimore), in which only three MAG author profiles contain more than five papers, <lb/>and the rest contain only one or two papers each. Figure 5 shows the three main author profile pages of David <lb/>Baltimore in the MAG API, suggesting that the three author profiles were considered different partly due to <lb/>a <lb/>b <lb/>c <lb/>Fig. 5 The three different MAG author profiles for Nobel laureate David Baltimore. MAG identified these as <lb/>three different authors partly due to the difference in affiliations: California Institute of Technology, Albert <lb/>Einstein College of Medicine, and Salk Institute for Biological Studies. We find that David Baltimore has indeed <lb/>worked at all three places, suggesting the correct way of identifying all his papers is to merge these MAG profiles <lb/>into one. [Image of David Baltimore was taken by Bob Paz and available for public use (https://en.wikipedia. <lb/>Creative Commons Attribution-Share Alike 3.0 license]. <lb/></body>

			<page>9 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<body>different affiliations: California Institute of Technology, Albert Einstein College of Medicine, and Salk Institute <lb/>for Biological Studies. We further checked his affiliations, finding that David Baltimore worked at Albert Einstein <lb/>College of Medicine, then moved to Salk Institute for Biological Studies in La Jolla as an independent research <lb/>associate, and he also served as the president of the California Institute of Technology (Caltech). We manually <lb/>checked all the papers under the 21 different MAG author profiles and calculate the accuracy. Manually counting <lb/>through the papers, we find the accuracy of our data is 97.3% within the 60 careers we selected. <lb/>Validation of the reproducibility of the dataset and method. In this paper, we adopt a <lb/>&quot;Seed + Expand&quot; procedure to solve the name disambiguation problems of Nobel laureates. The proposed method <lb/>is a hybrid procedure consisting of five steps, combining manual process and automatic algorithm. It is worth <lb/>noting that only step one needs a manual collection of laureates&apos; papers, and the other four steps (from step two <lb/>to step five) can be fulfilled automatically with established procedures and rules. The highly automated process of <lb/>our method guarantees the reproducibility of the dataset and method. <lb/>Together, we present a novel systematic dataset recording career information of Nobel laureates in science. <lb/>Although the curated data offers, to our knowledge, one of the most comprehensive publication records of Nobel <lb/>laureates so far, the goal of publishing this dataset is to allow all interested readers to help further refine and <lb/>improve the quality of the data. <lb/>references <lb/></body>

			<listBibl>1. Fortunato, S. et al. Science of science. Science 359, eaao0185, https://doi.org/10.1126/science.aao0185 (2018). <lb/>2. Azoulay, P. et al. Toward a more scientific science. Science 361, 1194-1197, https://doi.org/10.1126/science.aav2484 (2018). <lb/>3. Zeng, A. et al. The science of science: From the perspective of complex systems. Phys. Rep. 714, 1-73, https://doi.org/10.1016/j. <lb/>physrep.2017.10.001 (2017). <lb/>4. Wang, D. S., Song, C. M. &amp; Barabasi, A. L. Quantifying long-term scientific impact. Science 342, 127-132, https://doi.org/10.1126/ <lb/>science.1237825 (2013). <lb/>5. Mukherjee, S., Romero, D. M., Jones, B. &amp; Uzzi, B. The nearly universal link between the age of past knowledge and tomorrow&apos;s <lb/>breakthroughs in science and technology: The hotspot. Sci. Adv. 3, e1601315, https://doi.org/10.1126/sciadv.1601315 (2017). <lb/>6. Uzzi, B., Mukherjee, S., Stringer, M. &amp; Jones, B. Atypical combinations and scientific impact. Science 342, 468-472, https://doi. <lb/>org/10.1126/science.1240474 (2013). <lb/>7. Garfield, E. Citation Indexing: Its Theory and Application in Science, Technology, and Humanities. (Isi Press, 1979). <lb/>8. Garfield, E. Citation analysis as a tool in journal evaluation. Science 178, 471-479, https://doi.org/10.1126/science.178.4060.471 <lb/>(1972). <lb/>9. Radicchi, F., Fortunato, S. &amp; Castellano, C. Universality of citation distributions: Toward an objective measure of scientific impact. <lb/>Proc. Natl Acad. Sci. USA 105, 17268-17272, https://doi.org/10.1073/pnas.0806977105 (2008). <lb/>10. Liu, L. et al. Hot streaks in artistic, cultural, and scientific careers. Nature 559, 396-399, https://doi.org/10.1038/s41586-018-0315-8 <lb/>(2018). <lb/>11. Sinatra, R., Wang, D., Deville, P., Song, C. &amp; Barabási, A. L. Quantifying the evolution of individual scientific impact. Science 354, <lb/>aaf5239, https://doi.org/10.1126/science.aaf5239 (2016). <lb/>12. Jones, B. F. Age and great invention. Rev. Econ. Stat. 92, 1-14, https://doi.org/10.1162/rest.2009.11724 (2010). <lb/>13. Jones, B. F. The burden of knowledge and the &quot;death of the renaissance man&quot;: Is innovation getting harder? Rev. Econ. Stud 76, <lb/>283-317, https://doi.org/10.1111/j.1467-937X.2008.00531.x (2009). <lb/>14. Clauset, A., Arbesman, S. &amp; Larremore, D. B. Systematic inequality and hierarchy in faculty hiring networks. Sci. Adv. 1, e1400005, <lb/>https://doi.org/10.1126/sciadv.1400005 (2015). <lb/>15. Way, S. F., Morgan, A. C., Clauset, A. &amp; Larremore, D. B. The misleading narrative of the canonical faculty productivity trajectory. <lb/>Proc. Natl Acad. Sci. USA 114, E9216-E9223, https://doi.org/10.1073/pnas.1702121114 (2017). <lb/>16. Petersen, A. M. et al. Reputation and impact in academic careers. Proc. Natl Acad. Sci. USA 111, 15316-15321, https://doi. <lb/>org/10.1073/pnas.1323111111 (2014). <lb/>17. Zuckerman, H. Scientific elite: Nobel laureates in the United States. (Free Press, 1977). <lb/>18. Merton, R. K. The Matthew effect in science. Science 159, 56-63, https://doi.org/10.1126/science.159.3810.56 (1968). <lb/>19. Jones, B. F. &amp; Weinberg, B. A. Age dynamics in scientific creativity. Proc. Natl Acad. Sci. USA 108, 18910-18914, https://doi. <lb/>org/10.1073/pnas.1102895108 (2011). <lb/>20. Simonton, D. K. Creative productivity: A predictive and explanatory model of career trajectories and landmarks. Psychol. Rev. 104, <lb/>66-89, https://doi.org/10.1037/0033-295x.104.1.66 (1997). <lb/>21. Simonton, D. K. Genius, Creativity, and Leadership. (Harvard University Press, 1984). <lb/>22. Moreira, J. A. G., Zeng, X. H. T. &amp; Amaral, L. A. N. The distribution of the asymptotic number of citations to sets of publications by <lb/>a researcher or from an academic department are consistent with a discrete lognormal model. Plos One 10, e0143108, https://doi. <lb/>org/10.1371/journal.pone.0143108 (2015). <lb/>23. Wu, L., Wang, D. &amp; Evans, J. A. Large teams develop and small teams disrupt science and technology. Nature, 566, 378-382, https:// <lb/>doi.org/10.1038/s41586-019-0941-9 (2017). <lb/>24. Wuchty, S., Jones, B. F. &amp; Uzzi, B. The increasing dominance of teams in production of knowledge. Science 316, 1036-1039, https:// <lb/>doi.org/10.1126/science.1136099 (2007). <lb/>25. Milojevic, S. Principles of scientific research team formation and evolution. Proc. Natl Acad. Sci. USA 111, 3984-3989, https://doi. <lb/>org/10.1073/pnas.1309723111 (2014). <lb/>26. Newman, M. E. J. Coauthorship networks and patterns of scientific collaboration. Proc. Natl Acad. Sci. USA 101, 5200-5205, https:// <lb/>doi.org/10.1073/pnas.0307545100 (2004). <lb/>27. Shen, H. W. &amp; Barabasi, A. L. Collective credit allocation in science. Proc. Natl Acad. Sci. USA 111, 12325-12330, https://doi. <lb/>org/10.1073/pnas.1401992111 (2014). <lb/>28. Zuckerman, H. Nobel laureates in science: Patterns of productivity, collaboration, and authorship. Am. Sociol. Rev. 32, 391-403, <lb/>https://doi.org/10.2307/2091086 (1967). <lb/>29. Zuckerman, H. The sociology of the Nobel prizes. Sci. Am. 217, 25-33, https://doi.org/10.1038/scientificamerican1167-25 (1967). <lb/>30. Fortunato, S. Growing time lag threatens Nobels. Nature 508, 186-186, https://doi.org/10.1038/508186a (2014). <lb/>31. Nobel reactions. Nat. Phys. 13, 921-921, https://doi.org/10.1038/nphys4296 (2017). <lb/>32. Chan, H. F. &amp; Torgler, B. Time-lapsed awards for excellence. Nature 500, 29-29, https://doi.org/10.1038/500029c (2013). <lb/>33. Mazloumian, A., Eom, Y. H., Helbing, D., Lozano, S. &amp; Fortunato, S. How citation boosts promote scientific paradigm shifts and <lb/>nobel prizes. PLoS One 6, e18975, https://doi.org/10.1371/journal.pone.0018975 (2011). <lb/>34. Hansson, N., Halling, T. &amp; Fangerau, H. Nobel nomination letters point to a winning formula. Nature 555, 311, https://doi. <lb/>org/10.1038/d41586-018-03057-z (2018). <lb/></listBibl>

			<page>10 <lb/></page>

			<note place="footnote">Scientific Data | <lb/>(2019) 6:33 | https://doi.org/10.1038/s41597-019-0033-6 <lb/></note>

			<note place="headnote">www.nature.com/scientificdata <lb/>www.nature.com/scientificdata/ <lb/></note>

			<listBibl>35. Seeman, J. I. Synthesis and the Nobel prize in chemistry. Nat. Chem 9, 925-929, https://doi.org/10.1038/nchem.2864 (2017). <lb/>36. Fleming, L., Mingo, S. &amp; Chen, D. Collaborative brokerage, generative creativity, and creative success. Admin. Sci. Quart. 52, <lb/>443-475, https://doi.org/10.2189/asqu.52.3.443 (2007). <lb/>37. Singh, J. &amp; Fleming, L. Lone inventors as sources of breakthroughs: Myth or reality? Manage. Sci. 56, 41-56, https://doi.org/10.1287/ <lb/>mnsc.1090.1072 (2010). <lb/>38. Azoulay, P., Stuart, T. &amp; Wang, Y. B. Matthew: Effect or fable? Manage. Sci. 60, 92-109, https://doi.org/10.1287/mnsc.2013.1755 <lb/>(2014). <lb/>39. Vuong, Q. H. et al. An open database of productivity in Vietnam&apos;s social sciences and humanities for public use. Sci. Data 5, 180188, <lb/>https://doi.org/10.1038/sdata.2018.188 (2018). <lb/>40. Morrison, G., Riccaboni, M. &amp; Pammolli, F. Disambiguation of patent inventors and assignees using high-resolution geolocation <lb/>data. Sci. Data 4, 170064, https://doi.org/10.1038/sdata.2017.64 (2017). <lb/>41. Chan, H. F., Onder, A. S. &amp; Torgler, B. The first cut is the deepest: repeated interactions of coauthorship and academic productivity <lb/>in Nobel laureate teams. Scientometrics 106, 509-524, https://doi.org/10.1007/s11192-015-1796-y (2016). <lb/>42. Li, J. &amp; Shi, D. B. Sleeping beauties in genius work: When were they awakened? J. Assoc. Inf. Sci. Tech 67, 432-440, https://doi. <lb/>org/10.1002/asi.23380 (2016). <lb/>43. Li, J., Yin, Y., Fortunato, S., &amp; Wang, D. A dataset of publication records for Nobel laureates. Harvard Dataverse, https://doi. <lb/>org/10.7910/DVN/6NJ5RN (2018). <lb/>44. Li, J., Yin, Y., Fortunato, S. &amp; Wang, D. Nobel laureates are almost the same as us. Nat. Rev. Phys. In Press (2019). <lb/>45. Sinha, A. et al. In Proceedings of the 24th International Conference on World Wide Web 243-246, https://doi.org/10.1145/2740908.2742839 <lb/>(ACM, 2015). <lb/>46. Ferreira, A. A., Goncalves, M. A. &amp; Laender, A. H. F. A brief survey of automatic methods for author name disambiguation. Sigmod. <lb/>Rec 41, 15-26 (2012). <lb/>47. Smalheiser, N. R. &amp; Torvik, V. I. Author name disambiguation. Annu. Rev. Inform. Sci 43, 287-313 (2009). <lb/>48. Tang, J. et al. In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 990-998, <lb/>https://doi.org/10.1145/1401890.1402008 (ACM, 2008). <lb/>49. Dong, Y., Ma, H., Shen, Z. &amp; Wang, K. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery <lb/>and Data Mining 1437-1446, https://doi.org/10.1145/3097983.3098016 (ACM, 2017). <lb/>50. Reijnhoudt, L., Costas, R., Noyons, E., Börner, K. &amp; Scharnhorst, A. &apos;Seed + expand&apos;: a general methodology for detecting <lb/>publication oeuvres of individual researchers. Scientometrics 101,1403-1417, https://doi.org/10.1007/s11192-014-1256-0 (2014). <lb/>51. Zhu, X. &amp; Ghahramani, Z. Learning from labeled and unlabeled data with label propagation. Report No. CMU-CALD-02-107 <lb/>(Carnegie Mellon University, 2002). <lb/></listBibl>

			<div type="acknowledgement">acknowledgements <lb/>The authors thank L. Liu, Y. Wang, Y. Ma, B. Uzzi, and all members of Northwestern Institute on Complex Systems <lb/>(NICO) for invaluable comments. This work is supported by the Air Force Office of Scientific Research under <lb/>award number FA9550-15-1-0162 and FA9550-17-1-0089, National Science Foundation grant SBE 1829344 and <lb/>Northwestern University&apos;s Data Science Initiative. <lb/></div>

			<div type="annex">Author Contributions <lb/>D.W. led the project and prepared the manuscript; D.W. and S.F. designed the research; L.J. collected the data; Y.Y. <lb/>and L.J. preprocessed the data. All authors contributed to the text of the manuscript. <lb/>additional Information <lb/>Competing Interests: The authors declare no competing interests. <lb/>Publisher&apos;s note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and <lb/>institutional affiliations. <lb/></div>

			<front>Open Access This article is licensed under a Creative Commons Attribution 4.0 International <lb/>License, which permits use, sharing, adaptation, distribution and reproduction in any medium or <lb/>format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Cre-<lb/>ative Commons license, and indicate if changes were made. The images or other third party material in this <lb/>article are included in the article&apos;s Creative Commons license, unless indicated otherwise in a credit line to the <lb/>material. If material is not included in the article&apos;s Creative Commons license and your intended use is not per-<lb/>mitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the <lb/>copyright holder. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/. <lb/>The Creative Commons Public Domain Dedication waiver http://creativecommons.org/publicdomain/zero/1.0/ <lb/>applies to the metadata files associated with this article. <lb/>© The Author(s) 2019 </front>


	</text>
</tei>
