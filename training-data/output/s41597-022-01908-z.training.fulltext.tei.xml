<?xml version="1.0" ?>
<tei xml:space="preserve">
	<teiHeader>
		<fileDesc xml:id="0"/>
	</teiHeader>
	<text xml:lang="en">
			<head>Background &amp; Summary<lb/></head>

			<p>The reuse of text has a longstanding history in science. In qualitative research, besides verbatim quotations, the<lb/> techniques of paraphrasing, translation, and summarization are instrumental to both teaching and learning<lb/> scientific writing as well as to gaining new scientific insights <ref type="biblio">1</ref> . In quantitative research, the use of templates as<lb/> an efficient way of reporting new results on otherwise standardized workflows is common <ref type="biblio">2</ref> . As science often<lb/> progresses incrementally, authors may also reuse their texts across (different types of) subsequent publications<lb/> on the same subject (also called &quot;text recycling&quot;) <ref type="biblio">2-4</ref> . Likewise, in interdisciplinary research, reuse across publica-<lb/>tions at venues of different disciplines has been observed to better promote the dissemination of new insights <ref type="biblio">5,6</ref> .<lb/> Independent of all these manifestations of text reuse is the academic context that establishes their legitimacy:<lb/> In certain circumstances, any of them may be considered plagiarism, i.e., intentional reuse of a text without<lb/> acknowledging the original source, in violation of the honor code and academic integrity <ref type="biblio">7</ref> .<lb/></p>

			<p>Text reuse has been quantitatively studied in many scientific disciplines <ref type="biblio">1,2,8-10</ref> ; yet few studies assess the phenom-<lb/>enon at scale beyond what can be manually analyzed <ref type="biblio">9,10</ref> . Large-scale studies require the use of automatic text reuse<lb/> detection technology. This being both algorithmically challenging and computationally expensive, lack of expertise<lb/> or budget may have prevented such studies. Employing proprietary analysis software or services instead, too, is sub-<lb/>ject to budgetary limitations, in addition to their lack of methodological transparency and reproducibility.<lb/></p>

			<p>Text reuse detection itself is still subject to ongoing research in natural language processing and information<lb/> retrieval. Setting up a custom processing pipeline thus demands an evaluation against the state of the art. The<lb/> challenges in constructing a competitive solution for this task arise from the aforementioned diversity of differ-<lb/>ent forms of text reuse, the large solution space of detection approaches, and the need to apply heuristics that<lb/> render a given solution sufficiently scalable. Preprocessing a collection of scientific publications, too, presents<lb/> its own difficulties. This includes the noisy and error-prone conversion of publications&apos; original PDF versions to<lb/> machine-readable texts and the collection of reliable metadata about the publications. The available quantitative<lb/> studies on scientific text reuse lack with respect to the presentation of preprocessing steps taken, the design<lb/> choices of the solution to text reuse detection, and their justification in terms of rigorous evaluation. Altogether,<lb/> comparable, reproducible, reliable, and accessible research on the phenomenon of scientific text reuse remains<lb/> an open problem.<lb/></p>

			<p>To provide for a solid new foundation for the investigation of scientific text reuse within and across dis-<lb/>ciplines, we compile Webis-STEREO-21. To overcome the aforementioned issues, we stipulate three design<lb/> principles for the creation of the dataset: (1) high coverage, both in terms of the number of included publications<lb/> and the variety of scientific disciplines; (2) a scalable approach to reuse detection with a focus on high preci-<lb/>sion at a competitive recall, capturing a comprehensive set of reused passages as reliable resource for research<lb/> on scientific text reuse; and (3) comprehensive metadata to contextualize each case, to address a wide range of<lb/> potential hypotheses.<lb/></p>

			<p>Webis-STEREO-21 results from applying scalable text reuse detection approaches to a large collection of<lb/> scientific open-access publications, exhaustively comparing all documents to extract a comprehensive dataset<lb/> of reused passages between them. It contains more than 91 million cases of reused passages among 4.2 million<lb/> unique publications. The cases stem from 46 scientific fields of study, grouped into 14 scientific areas in all four<lb/> major scientific disciplines, and spanning over 150 years of scientific publishing between 1860 and 2018. The<lb/> data is openly accessible to be useful to a wide range of researchers with different scientific backgrounds, ena-<lb/>bling both qualitative and quantitative analysis.<lb/></p>

			<head>Methods<lb/></head>

			<p>To create a dataset of text reuse in scientific texts, four things are needed: an operationalization of the phenom-<lb/>enon of text reuse, a large collection of scientific publications, detailed metadata for each of these publications,<lb/> and a scalable yet effective method for detecting reuse in these publications. In this section we describe all four,<lb/> explaining the latter both generally and formally to ensure their reproducibility. Figure <ref type="figure">1</ref> illustrates the process-<lb/>ing pipeline for the creation of the dataset.<lb/></p>

			<head>An operationalization of text reuse.</head>

			<p>To reuse something means to use it again after the first time. Reused<lb/> text is text that is primarily, if not exclusively, derived from another text. In academic writing, writing techniques<lb/> for reusing a text include boilerplate, quotation, paraphrasing, and summarizing. What all these techniques have<lb/> in common is that a reused text and its original have a certain kind of similarity that the reader can recognize <ref type="biblio">11</ref> .<lb/> Manual identification of text reuse between two given texts is therefore based on the identification of the relevant<lb/> text passages where such similarities can be detected.<lb/></p>

			<p>To operationalize this notion of reuse, a suitable text similarity measure and a similarity threshold have to be<lb/> chosen, where a pair of texts has to exceed the threshold in order to be considered potential reuse. We broadly<lb/> distinguish similarity measures that operate at the syntactic level from measures that operate at the semantic<lb/> level of language, where the former capture the &quot;reuse of words&quot; and the latter the &quot;reuse of ideas&quot; <ref type="biblio">12</ref> .<lb/></p>

			<p>In practice, text reuse detection relies heavily on syntactic similarity detection <ref type="biblio">13,14</ref> . Syntactic reuse is relatively<lb/> easy to visualize and consequently faster to check than semantic reuse <ref type="biblio">15</ref> . The former can be checked by distant<lb/> reading, the latter requires close reading, which causes high costs with increasing text length <ref type="biblio">16</ref> . Similarly, it can<lb/> be assumed that semantic reuse is much less common than syntactic reuse, since the most common goal of text<lb/> reuse is to save time and cognitive effort, whereas the time savings of semantic reuse are generally lower <ref type="biblio">17</ref> .<lb/></p>

			<p>We opt for a conservative similarity analysis at the syntactic level, measuring the correspondence between<lb/> the surface forms of words occurring in two given texts and the phrases formed from them. This design decision<lb/> is also motivated by the target domain: In addition to the contribution of new ideas, a large fraction of scientific<lb/> contributions describe reflection on as well as advances to known ideas, and the development of solutions to<lb/> tasks and problems up to the point of transfer to practice. A semantic similarity score in this context would<lb/> rather lead to a citation graph mixing natural matches of ideas with intended reuse. It is in the nature of current<lb/> semantic similarity measures that they often capture even minor and distant similarities, leading to significant<lb/> noise in the form of false positives in tasks such as text reuse detection. Also, detection at the syntactic level<lb/></p>

			<figure type="table">Webis STEREO-21<lb/> 91,466,374 Text Reuse Cases<lb/> Publication Database<lb/> 4,656,302 PDF Files<lb/> Preprocessing<lb/> Text Alignment<lb/> Source Retrieval<lb/> Metadata<lb/></figure>

			<p>Fig. <ref type="figure">1</ref> Schematic overview of the text reuse detection pipeline. Each document is pre-processed and supplied<lb/> with metadata. Source retrieval identifies document pairs with local similarities, and alignment is applied to<lb/> identify reuse cases between those.<lb/> is more in line with the concept of text reuse used in practice.In other words, &apos;similar&apos; here refers to an over-<lb/>lap in the vocabulary and wording of two documents, an operationalization common to large-scale text reuse<lb/> detection <ref type="biblio">18</ref> .<lb/></p>

			<p>Although even a single word overlap between two pieces of text, such as a specific and unlikely spelling mis-<lb/>take, can be sufficient as a strong indication of reuse, automatic methods are not yet able to reliably detect such<lb/> cases. Instead, several overlaps of words and phrases are required that occur in close proximity to each other<lb/> in both texts, thus forming potentially reused text passages. Such passages are not necessarily verbatim copies:<lb/> Words and phrases may be added, removed, or changed, and sentences may be rearranged. Nevertheless, suffi-<lb/>cient overlap must remain, which can be modeled by the similarity threshold parameter mentioned above. This<lb/> parameter cannot be derived formally, but must be determined empirically.<lb/></p>

			<p>This operationalization of text reuse, and thus the cases included in our dataset, are orthogonal to the ques-<lb/>tion of the legitimacy of reuse. Thus, the notion of &quot;text reuse&quot; is explicitly not limited to or equated with &quot;plagia-<lb/>rism. &quot; We do not draw any conclusions from the fact that two documents have a reused passage in common, but<lb/> merely observe that there is one. The distinction between original and plagiarized text cannot and should not be<lb/> an algorithmic decision <ref type="biblio">19</ref> . Further limitations are discussed in the Usage Notes section.<lb/></p>

			<p>Text reuse detection in large document collections. Detecting all reuses of text in a collection of doc-<lb/>uments is a problem of high computational complexity. Each document must be compared pairwise with every<lb/> other document in the collection. So for N documents, N•(N-1) document-to-document comparisons must be<lb/> made. Each individual comparison requires a considerable amount of time and resources, so that the processing<lb/> of larger collections of documents exceeds even large computational capacities. In order to still be able to analyze<lb/> large document collections for text reuse, the set of comparisons is pruned by filtering out document pairs that<lb/> are guaranteed not to exhibit text reuse according to our operationalization.<lb/> This is achieved through a two-step process: first, a cheap-to-compute heuristic is applied to identify candi-<lb/>date pairs of documents where text reuse is likely. Then, the expensive document comparison is performed only<lb/> for the candidate pairs identified in this way. All other pairs are skipped.The first step of this two-part process<lb/> is commonly called a source retrieval <ref type="biblio">20</ref> , while the second step is called text alignment <ref type="biblio">21</ref> . The result of the whole<lb/> process is a set of cases of text reuse between documents in the collection. A case of text reuse is modeled here as<lb/> a pair of text passages, one in each document involved in the comparison, that have sufficient overlap of words<lb/> and phrases, along with references to their source documents and where exactly they are found in them.<lb/></p>

			<p>While source retrieval greatly improves the efficiency of the overall process, it introduces an error in the form<lb/> of reduced recall, i.e., pairs of reused passages are overlooked that would have been discovered by an exhaustive<lb/> comparison of each pair of documents. The goal of source retrieval is therefore to filter out only those document<lb/> pairs for which the text alignment step will not find any reused passages, which is to be expected for the vast<lb/> majority of all document pairs. We choose the source retrieval parameters conservatively, so that only those<lb/> document pairs are skipped for which the text alignment is guaranteed to return no result.<lb/></p>

			<p>Publication acquisition, preprocessing and metadata. Detecting scientific text reuse and contextual-<lb/>izing it on a large scale requires a large collection of scientific publications and detailed metadata about them. We<lb/> compiled such a dataset in the five steps of document selection, plain text extraction, text preprocessing, metadata<lb/> acquisition, and metadata standardization.<lb/></p>

			<p>We build on the CORE dataset <ref type="biblio">22</ref> , one of the largest collections of open-access scientific publications sourced<lb/> from more than 12,000 data providers. First, we identify the 6,015,512 unique open-access DOIs in the March<lb/> 1, 2018 CORE dataset. Since the plain texts extracted from the PDF files of the publications, as provided by the<lb/> CORE data, are of varying quality and no structural annotations (such as markup for citations, in-text refer-<lb/>ences, section annotations) are available, we chose to obtain the original PDF files of the identified open-access<lb/> DOIs from various publicly available repositories.<lb/></p>

			<p>The plain text extraction has been repeated on the acquired PDF files using the standardized state-of-the-art<lb/> toolchain GROBID <ref type="biblio">23</ref> . A minimum of 1,000 and a maximum of 60,000 space-separated words are introduced<lb/> as an effective heuristic to filter out common plaintext extraction errors. In total, we obtained and extracted<lb/> clean plaintext for 4,267,166 documents (70% of the open access publications in the original CORE dataset).<lb/> Since text alignment analyzes word overlaps between documents, the highly standardized meta-information in<lb/> scientific texts such as citations, numbers, author names, affiliations, and references lead to exponentially more<lb/> false-positive detections of reuse than without them. Therefore, text alignment processes the abstract and main<lb/> body of a document without in-text references, tables, figures, bibliographic data, and numeric data, while nor-<lb/>malizing or removing special characters, which minimizes the false positives observed in preliminary studies.<lb/> However, research on text reuse and its evaluation on a case-by-case basis benefits from, or even requires, the<lb/> in-text metadata mentioned above, so that two versions of each text passage involved in a reuse case were kept:<lb/> the one that came from GROBID, including the aforementioned information except for tables and images, and,<lb/> the one that was fed into the text alignment.<lb/></p>

			<p>Based on the detections, we augment the metadata provided by CORE with additional data from the<lb/> Microsoft Open Academic Graph (OAG) <ref type="biblio">24,25</ref> , which contains study field annotations for a large number of publi-<lb/>cations. Metadata is assigned by matching records in CORE and OAG using an article&apos;s DOI identifier. Since the<lb/> annotated disciplines in the OAG do not follow a hierarchical scheme and since they are of different granularity<lb/> per publication (e.g., &quot;humanities&quot; as a whole vs. &quot;chemical solid state research&quot; as a subfield of chemistry), we<lb/> manually map the classification found in the OAG to the standard hierarchical DFG Classification of Scientific<lb/> Disciplines, Research Areas, Review Boards and Subject Areas <ref type="biblio">26</ref> . We have chosen to replace the term &quot;review<lb/> board&quot; used in the DFG classification with the more conventional term &quot;field of study&quot;. The mapping was done<lb/> by three people independently. In the few cases where there was disagreement, consensus was reached through<lb/> discussion. The final mapping includes 46 individual scientific fields of study drawn from 14 scientific areas and<lb/> four major scientific disciplines.<lb/></p>

			<head>Source retrieval.</head>

			<p>An exhaustive comparison of all four million publications greatly exceeds the available<lb/> computing capacity. Therefore, a source retrieval step has to be carried out first <ref type="biblio">27,28</ref> . By applying suitable heuris-<lb/>tics, the source retrieval step can be operationalized with linear time complexity with respect to the document<lb/> count <ref type="biblio">29</ref> , compared to the quadratic expenditure of an exhaustive comparison.<lb/></p>

			<p>The source retrieval component of our pipeline, i.e., the computation of all candidate comparisons D d for a<lb/> given document d, is operationalized by treating text reuse as a locally bounded phenomenon. Candidate pairs<lb/> are presumed to be identifiable by comparing text passages between two documents. If the similarity is suffi-<lb/>ciently high for at least one combination of passages between two documents d and d′, then d′ is considered a<lb/> candidate for d.<lb/></p>

			<p>To achieve high scalability, we implement the similarity computation by applying locality-sensitive hash func-<lb/>tions h to each passage t in a document d, thus representing each document&apos;s passages with a set of hash values<lb/> h(t). These can be interpreted as a set of fingerprints, encoding the characteristics of each passage in a document<lb/> in compressed form. The similarity between two passages t and t′ stemming from two different documents d and<lb/> d′ is then approximated by the extent of overlap between their hash sets, h t<lb/> h t<lb/> ( )<lb/> ( )<lb/></p>

				<formula>∩ ′ .</formula>

			<figure type="table">Thus, a document d′ is<lb/> considered a candidate source of text reuse for a document d, if at least one of their passage-level hash sets inter-<lb/>sects 29 : ∃ ⊆<lb/> t d and t<lb/> d h t<lb/> h t<lb/> : ( )<lb/> ( )<lb/></figure>

				<formula>∩<lb/> φ<lb/> ∃ ′ ⊆ ′<lb/> ′ ≠ .</formula>

			<p>This means that two documents have to share at least one of the<lb/> passage-level fingerprint hashes, i.e. have at least one common characteristic, to be deemed a candidate pair.<lb/></p>

			<p>In our pipeline, the documents are first divided into consecutive passages of n terms, which in turn are each<lb/> embedded using a bag-of-words representation, i.e., as their term occurrence vector. To find matching passages<lb/> between two documents, MinHash 30 is chosen as hashing scheme for h. For each passage vector, multiple indi-<lb/>vidual hash functions are applied to each element, and the minimum hash value of each pass is saved, yielding<lb/> the set minimum hashes for a passage. It can be shown that, for m individual hashes per passage, two texts with<lb/> a Jaccard similarity of at least m -1 are guaranteed to produce a hash collision between their hash sets, rendering<lb/> them a suitable approximation for the lower bound of document similarity <ref type="biblio">30</ref> . Applying this scheme to all pas-<lb/>sages in all documents, we detect all document pairs that are locally similar, i.e., which have a word overlap in<lb/> their bag-of-words passage representations. For example, if documents would be split into n = 20 word passages,<lb/> and m = 5 hash fingerprints are calculated per passage, two documents would be identified as pair if they share<lb/> at least 4 words across one of the respective passages. A document is never compared to itself.<lb/></p>

			<p>Hash-based source retrieval allows for a significant reduction of the required computation time, since the<lb/> hash-based approximation has a linear time complexity with respect to |D|, as opposed to the quadratic com-<lb/>plexity of vector comparisons <ref type="biblio">29</ref> . As a result, our source retrieval computation time could be fitted into the<lb/> allotted budget of two months of computing time on a 130-node Apache Spark cluster, with 12 CPU cores and<lb/> 196 GB RAM per node (1560 cores, 250 TB RAM total). Besides its efficiency, the outlined approach provides<lb/> us with a second highly beneficial characteristic-the source retrieval step depends on only two parameters: the<lb/> passage length n, which can be chosen according to computational constraints, and the number of hashes m,<lb/> which is chosen according to the required minimum similarity separating two passages. By choosing this bound<lb/> of m -1 Jaccard similarity lower than the minimum detection threshold of the subsequent text alignment step,<lb/> the search space is pruned without a loss in accuracy. Thus, our hash-based similarity search primarily impacts<lb/> the precision, but not the recall of the source retrieval step with respect to the subsequent text alignment step.<lb/></p>

			<p>Text alignment. Based on the reduced set of comparison candidates D d obtained by source retrieval, the text<lb/> alignment component extracts the exact location of the reused passages of each candidate pair of documents d<lb/> and d′ inD d . Here we follow the seed-and-extend approach to local sequence alignment <ref type="biblio">31</ref> . The two-step process is<lb/> illustrated in Fig. <ref type="figure">2</ref>. First, both texts are divided into small chunks (&apos;chunking&apos;). Then, the matching chunks in the<lb/> Cartesian product of the two sets of chunks are computed according to a similarity function ϕ. Its purpose is to<lb/> identify matching textual chunks (&apos;seeds&apos;&apos;) between two documents d and d′ that have the same meaning or can<lb/> be considered instances of the same concept. Finally, sufficiently close matches are combined into larger passages<lb/> (&apos;extension&apos;). Such a pair of passages</p>

				<formula>⊆<lb/> ′ ⊆ ′<lb/> t d t<lb/> d<lb/> (<lb/> ,<lb/></formula>

			<p>) in both documents is then output probable reuse case.<lb/> With respect to the chunking and seeding steps, two methodological decisions must be made. First, how to<lb/> divide a given document into small chunks. And second, which similarity function should be used to compare<lb/></p>

			<figure>d<lb/> d &apos;<lb/> d<lb/> d&apos;<lb/> d<lb/> d &apos;<lb/> Chunking<lb/> S eeding<lb/> E xtending<lb/> Fig. 2 Schematic overview of the text alignment process. Each document is divided into chunks, matching<lb/> chunks are identified between documents, and matches are extended to whole reuse cases.<lb/></figure>

			<p>pairs of text chunks to determine whether they have the same meaning. A widely used approach to the former,<lb/> which has been shown to produce accurate results, is to divide a text into (word) n-grams, i.e., contiguous<lb/> chunks of words of length n <ref type="biblio">9,32</ref> . These n-grams are overlapping and are created by &quot;sliding&quot; a window over the<lb/> text. For example, the sentence &quot;The quick brown fox jumps over the lazy dog. &quot; consists of the 4-grams &quot;The<lb/> quick brown fox&quot;, &quot;quick brown fox jumps&quot;, &quot;brown fox jumps over&quot;, &quot;fox jumps over the&quot;, &quot;jumps over the lazy&quot;,<lb/> and &quot;over the lazy dog&quot; at an overlap of three words. The n-gram chunks of the two documents d and d′ are then<lb/> exhaustively compared, i.e., every part of d is compared to every part of d′. As a similarity function, we again<lb/> use a hash function, but a string hash function rather than a locale-sensitive function. This choice enables a<lb/> linear-time comparison of the Cartesian product. Two parameters can be modified in this approach: the n-gram<lb/> size n, and the n-gram overlap k.<lb/> The matching chunks found through hash collisions indicate &quot;seeds&quot; of a potentially longer case of reused<lb/> text. To determine whether such a case can be found, the extension step joins co-aligned matching chunks<lb/> into longer passages when a sufficient number are found close to each other. In this manner, not only cases<lb/> of coherent reuse, but also cases where text was copied and then paraphrased can be detected. For example, if<lb/> consecutive sentences in a source text are copied into a target text, and then another (new) sentence is placed<lb/> in between them, this would be still considered a case of coherent reuse. Seeding would succeed in identifying<lb/> the two copied sentences on their own, yet the extension recognizes that both seeds are in close proximity in<lb/> both documents, and thus outputs a single case of reuse including both. The opposite case is also possible: two<lb/> chunks from different locations in a source text are placed close to each other in the target texts. Here, again, an<lb/> extension is required to reconstruct the full scope of reuse. Note that the extension approach depends on a single<lb/> parameter, Δ, which is the maximum distance in characters for two seeds in either of a pair of documents below<lb/> which a single reuse case is assumed <ref type="biblio">32</ref> .<lb/></p>

			<p>We supply a massively parallelizeable implementation of both the source retrieval and text alignment step,<lb/> which allows for detecting text reuse in the highly scalable manner needed given the amount and length of<lb/> input documents: 4.2 million publications, totaling 1.1 terabytes of text data. Overall, the text alignment step<lb/> accounted for an additional 3.5 months of computing time on the aforementioned Spark cluster.<lb/></p>

			<head>Data records<lb/></head>

			<p>Two types of data records are included in the Webis-STEREO-21 corpus: the reuse case data, which con-<lb/>tains all identified cases of text reuse alongside their metadata, and the publication data for each individual<lb/> document considered when computing the cases, including publication year and field of study annotations. The<lb/> records can be cross-referenced using a publications&apos; DOI as primary key. The corpus consists of two archive<lb/> files: cases.tar.gz contains the reuse case data, while publications.tar.gz contains the publication<lb/> data. Each of these archives bundles multiple partial files in the JSONL format, where every line corresponds to<lb/> a unique JSON-encoded case or publication. The Webis-STEREO-21 corpus is archived at Zenodo (https://<lb/> doi.org/10.5281/zenodo.5575285 <ref type="biblio">33</ref> ).<lb/></p>

			<p>Each of the 91,466,374 identified cases of potential text reuse is represented as an individual entry, refer-<lb/>encing two different publications. A pair of publications can contain multiple occurrences of text reuse, each of<lb/> which is treated as a unique case and entry. Each case encompasses two kinds of metadata: (1) locators, which<lb/> identify the matched text by its in-text location, using character offsets to mark start and end, and (2) context<lb/> about the publications involved in the case both by year and by field of study. In the context of a case, we refer<lb/> to the first involved publication as a, and to the second as b. This, however, does not indicate a directionality of<lb/> reuse in terms of publication time. Table <ref type="table">1</ref> gives a detailed overview on all data fields available.<lb/></p>

			<p>In the publication data, the metadata for all 4,267,166 documents considered for reuse computation is pro-<lb/>vided. Not every document is involved in at least one reuse case. Publications without detected reuse where<lb/> included to help contextualize analyses derived from the case data, providing baseline data about distribution<lb/> of metadata such as fields of study. Table <ref type="table">2</ref> provides detailed information about the fields available for each<lb/> publication.<lb/></p>

			<head>technical Validation<lb/></head>

			<p>This section motivates and details the parameter choices for the source retrieval and text alignment components<lb/> of the text reuse detection pipeline. For both steps, we strive for maximum accuracy given the constraints for<lb/> scalability and computational efficiency imposed by the amount of data to be processed. To contextualize the<lb/> usability of the final dataset, key insights into the distribution of data are given as well.<lb/></p>

			<p>Source retrieval. Objective of the source retrieval step is to prune the search space of document pairs by<lb/> reducing the number of pairs to be compared in subsequent (computationally expensive) steps. The optimization<lb/> criterion is recall: Ideally, no document pair containing text reuse should be overlooked, i.e., the false negative<lb/> rate should be minimized.<lb/></p>

			<p>To allow for a fine-grained detection of local similarity, the parameters of the source retrieval step are set to<lb/> n = 50 and m = 10, i.e., documents are split into passages of 50 words, with 10 MinHash values computed per<lb/> passage. Consequently, the source retrieval is able to identify pairs of documents that share as little as a 9-word<lb/> overlap between any two passages. Note that these words do not need to be consecutive since passages are rep-<lb/>resented in a bag-of-words model. Since the subsequent alignment step operates at the 8-gram level (=eight<lb/> consecutive units, see next section), the filtering within the source retrieval step eliminates only pairs for which<lb/> the subsequent alignment step is guaranteed to not find any matches. Overall, the source retrieval step yields<lb/> 3.305 × 10 12 total unique document pairs for further analysis. Given the initial document count of 4,656,302, this<lb/> represents a pruning of the search space by over 84% compared to an exhaustive pairwise comparison, rendering<lb/> the source retrieval step highly effective in improving overall efficiency.<lb/></p>

			<p>Text alignment. The text alignment step identifies the exact location and extent of reuse between two doc-<lb/>uments. Unlike source retrieval, text alignment is a precision-oriented task: Special emphasis is put on precision<lb/> over recall for the parameter choice to minimize the number of false positives; a low noise ratio is paramount<lb/> for meaningful future analyses of the dataset. To ensure the effectiveness of the text alignment, its parameters<lb/> are chosen by performing a grid-search, using precision, recall, and F 0.5 as effectiveness scores. We employ the<lb/> PAN-13 Text Alignment Corpus for evaluation, which has been previously published as a benchmark dataset for<lb/> text alignment by the PAN Shared Task on Plagiarism Detection <ref type="biblio">34</ref> . It contains 10,000 pairs of documents that are<lb/> subject to different so-called obfuscation strategies that simulate more difficult cases of plagiarism, where the<lb/> authors tried to hide text-reuse by paraphrasing the copied text to some extent.<lb/></p>

			<p>The applied obfuscation strategies include random obfuscation (shuffling, adding, deleting, and replac-<lb/>ing words or short phrases at random), cyclic translation obfuscation (a text is translated into another lan-<lb/>guage, and back to the original language; possibly with more languages in-between), summary obfuscation<lb/> (human-generated summaries of source texts), non-obfuscated plagiarism, and pairs of documents without<lb/> any text reuse between them. Each of these strategies is equally represented in the corpus with 2,000 pairs. The<lb/> grid search identifies an n-gram size of n = 8, an n-gram overlap of k = 7, and an extension range of Δ = 250 as<lb/> optimal. Under these conditions, our implementation of the text alignment step achieves a precision of 0.93 at<lb/> a recall of 0.46, and thus an F 0.5 score of 0.77. This renders our approach highly competitive when compared to<lb/> other approaches evaluated as part of the PAN Shared Tasks, placing it among the best for precision and F 0.5 ,<lb/> while being the only approach adhering to the scalability requirements imposed by the scale of our analysis.<lb/> A full overview of the attained scores for comparison with competing systems is given in Table <ref type="table">3</ref>.<lb/></p>

			<p>When evaluating separately per obfuscation strategy (Table <ref type="table">4</ref>), precision is very high throughout, exceeding<lb/> 0.88 in all cases. This fact places our system within 0.08 for the best-performing, yet computationally more<lb/> complex approach for each obfuscation strategy. Yet, a drop in recall can be observed for heavily obfuscated text,<lb/> down to 0.1 for summary obfuscation. This effect is expected and also noticeable among the other approaches<lb/> presented at PAN. Moreover, our focus is not on plagiarism but on establishing a general baseline for text reuse<lb/> in science, where more literal reuse (e.g., citations, idiomatic reuse, template writing, etc.) is expected to be the<lb/> norm. The heavily obfuscated test sets studied at PAN were dedicated to study extreme cases of plagiarism,<lb/></p>

			<figure type="table">Key<lb/> Description<lb/> Type<lb/> id<lb/> Unique identifier for this case, in UUID format.<lb/> String<lb/> Publication A<lb/> Locator<lb/> begin_a<lb/> Start location of matched text, measured as character offset. Integer<lb/> end_a<lb/> End location of matched text, measured as character offset. Integer<lb/> doc_length_a<lb/> Total length of publication A in characters.<lb/> Integer<lb/> Context<lb/> doi_a<lb/> DOI identifier for publication A.<lb/> String<lb/> year_a<lb/> Publication year for publication A.<lb/> Integer (optional)<lb/> field_a<lb/> Field(s) of study for publication A.<lb/> String Array (optional)<lb/> area_a<lb/> Scientific area(s) for publication A.<lb/> String Array (optional)<lb/> discipline_a<lb/> Scientific discipline(s) for publication A.<lb/> String Array (optional)<lb/> Publication B<lb/> Locator<lb/> begin_b<lb/> Start location of matched text, measured as character offset. Integer<lb/> end_b<lb/> End location of matched text, measured as character offset. Integer<lb/> doc_length_b<lb/> Total length of publication B in characters.<lb/> Integer<lb/> Context<lb/> doi_b<lb/> DOI identifier for publication B.<lb/> String<lb/> year_b<lb/> Publication year for publication B.<lb/> Integer (optional)<lb/> field_b<lb/> Field(s) of study for publication B.<lb/> String Array (optional)<lb/> area_b<lb/> Scientific area(s) for publication B.<lb/> String Array (optional)<lb/> discipline_b<lb/> Scientific discipline(s) for publication B.<lb/> String Array (optional)<lb/> Table 1. Data record overview for case data. Key denotes the top-level JSON key by which fields are identified,<lb/> Description provides an explanation of the contained data, and Type denotes the data type; &quot;optional&quot; indicates<lb/> fields that can be empty. The text fields are included only in the full version of the corpus.<lb/> Key<lb/> Description<lb/> Type<lb/> Metadata<lb/> doi<lb/> DOI identifier of the publication.<lb/> String<lb/> doc_length<lb/> Total length of the publication in characters. Integer<lb/> year<lb/> Publication year of the publication.<lb/> String Array (optional)<lb/> field<lb/> Field of study of the publication.<lb/> String Array (optional)<lb/> area<lb/> Scientific area of the publication.<lb/> String Array (optional)<lb/> discipline<lb/> Scientific discipline of the publication.<lb/> String Array (optional)<lb/> Table 2. Data record overview for publication data. Key denotes the top-level JSON key fields are identified by,<lb/></figure>

			<p>Description provides an explanation of the contained data, and Type denotes the data type; &quot;optional&quot; indicates<lb/> fields that can be empty.<lb/></p>

			<p>where an author expends much effort to hide the fact via severe forms of paraphrasing. The investment of such<lb/> an effort, however, goes against the time savings that can be expected from reusing text, so that it can be pre-<lb/>sumed that the vast amount of paraphrased text reuse will only make smaller changes to a text instead of chang-<lb/>ing every last n-gram. This observation is partially corroborated when reviewing the many cases of academic<lb/> plagiarism found in dissertation theses throughout the recent years <ref type="biblio">14</ref> , where extensive paraphrasing is hardly<lb/> ever observed. We therefore deemed the investment of an exponentially higher computation cost into retrieving<lb/> such cases to be uneconomical.<lb/> Nevertheless, two measures to tackle this recall issue have been proposed by PAN participants: (1) custom-<lb/>ized approaches for each of the different obfuscation strategies, employing heuristics to detect which kind a doc-<lb/>ument pair is exhibiting, and (2) ensemble methods encompassing different seeding and extension strategies,<lb/> combined into a single result. However, the first is not applicable to our situation, as there is no ground truth<lb/> data available to fine-tune such a classification to scientific writing. The second comes at a very high runtime<lb/> and algorithmic complexity. This is reflected in Table <ref type="table">3</ref> as well: for each approach, the (asymptotic) algorithmic<lb/> complexity is noted, for two given sequences of length n and m. Only six of the approaches presented at PAN<lb/> perform in sub-quadratic time, a necessary requirement for large-scale detection. Furthermore, the data spec-<lb/>ificity for each approach is listed: it denotes how much fine-tuning to the PAN data has taken place, for exam-<lb/>ple, by crafting specialized corpus-dependent features, using ensemble methods, trained classifiers, or specific<lb/> approaches for each of the different obfuscation strategies, all of which reduce the generalizability and transfer-<lb/>ability of the approaches to other data.<lb/></p>

			<p>Out of the four other approaches to combine sub-quadratic runtime complexity with low data specificity,<lb/> ours performs best with regard to recall and the F 0.5 score, and is second in precision by a very close margin.<lb/></p>

			<head>PAN13 Evaluation Corpus<lb/></head>

			<note type="other">Team<lb/> Precision ↓<lb/> Recall<lb/> F0.</note>

			<figure type="table">5<lb/> Complexity<lb/> Data Specificity<lb/> Glinos (2014)<lb/> 0.96<lb/> 0.79<lb/> 0.92 O(nm)<lb/> Medium<lb/> Jayapal (2012)<lb/> 0.95<lb/> 0.22<lb/> 0.57 O(n + m)<lb/> Low<lb/> Nourian (2013)<lb/> 0.95<lb/> 0.43<lb/> 0.76 -<lb/>-<lb/>Gross (2014)<lb/> 0.93<lb/> 0.77<lb/> 0.89 O(nm)<lb/> Low<lb/> Alvi (2014)<lb/> 0.93<lb/> 0.55<lb/> 0.82 O(n + m)<lb/> Medium<lb/> Ours<lb/> 0.93<lb/> 0.46<lb/> 0.77 O(n + m)<lb/> Low<lb/> Baseline (2014)<lb/> 0.93<lb/> 0.34<lb/> 0.69 O(n + m)<lb/> Low<lb/> Palkovskii (2014)<lb/> 0.92<lb/> 0.83<lb/> 0.90 O(nm)<lb/> High<lb/> Torrejon (2014)<lb/> 0.90<lb/> 0.77<lb/> 0.87 O(nm)<lb/> High<lb/> Gillam (2014)<lb/> 0.89<lb/> 0.17<lb/> 0.48 O(nm)<lb/> High<lb/> Oberreuter (2014)<lb/> 0.89<lb/> 0.86<lb/> 0.88 -<lb/>-<lb/>Oberreuter (2012)<lb/> 0.89<lb/> 0.77<lb/> 0.86 -<lb/>-<lb/>Gillam (2012)<lb/> 0.89<lb/> 0.27<lb/> 0.61 O(nm)<lb/> High<lb/> Torrejon (2013)<lb/> 0.89<lb/> 0.76<lb/> 0.86 O(nm)<lb/> High<lb/> Gillam (2013)<lb/> 0.88<lb/> 0.26<lb/> 0.60 O(nm)<lb/> High<lb/> Jayapal (2013)<lb/> 0.88<lb/> 0.38<lb/> 0.70 O(n + m)<lb/> Low<lb/> Sanchez-Perez (2014)<lb/> 0.88<lb/> 0.88<lb/> 0.88 O(nm)<lb/> High<lb/> Kueppers (2012)<lb/> 0.87<lb/> 0.51<lb/> 0.76 O(nm)<lb/> Low<lb/> Shrestha (2013)<lb/> 0.87<lb/> 0.74<lb/> 0.84 O(nm)<lb/> Medium<lb/> Saremi (2013)<lb/> 0.87<lb/> 0.77<lb/> 0.85 -<lb/>-<lb/>Shrestha (2014)<lb/> 0.86<lb/> 0.84<lb/> 0.86 O(nm)<lb/> Medium<lb/> Kong (2012)<lb/> 0.85<lb/> 0.82<lb/> 0.84 O(nm)<lb/> Low<lb/> Suchomel (2012)<lb/> 0.84<lb/> 0.65<lb/> 0.79 O(n + m)<lb/> Medium<lb/> Kong (2014)<lb/> 0.84<lb/> 0.81<lb/> 0.83 O(nm)<lb/> Low<lb/> Kong (2013)<lb/> 0.83<lb/> 0.81<lb/> 0.83 O(nm)<lb/> Low<lb/> Torrejon (2012)<lb/> 0.83<lb/> 0.75<lb/> 0.81 O(nm)<lb/> High<lb/> Palkovskii (2013)<lb/> 0.82<lb/> 0.54<lb/> 0.74 O(nm)<lb/> High<lb/> Palkovskii (2012)<lb/> 0.82<lb/> 0.76<lb/> 0.81 O(nm)<lb/> High<lb/> Abnar (2014)<lb/> 0.77<lb/> 0.61<lb/> 0.73 O(nm)<lb/> Medium<lb/> Suchomel (2013)<lb/> 0.73<lb/> 0.77<lb/> 0.74 O(n + m)<lb/> Medium<lb/> Sanchez-Vega (2012)<lb/> 0.40<lb/> 0.56<lb/> 0.42 O(nm)<lb/> Medium<lb/> Table 3. Precision, Recall, and F 0.5 score of competing alignment approaches by teams participating at the PAN<lb/> Shared Tasks, taken from Potthast et al. <ref type="biblio">34</ref> and Potthast et al. <ref type="biblio">39</ref> and sorted descending by precision. The listed<lb/> approaches are described in detail in the PAN Workshop proceedings <ref type="biblio">40-42</ref> . Complexity denotes the runtime<lb/> complexity of the approach; Data Specificity denotes the degree of PAN-specific optimizations reducing<lb/> transferability to other data domains, i.e. ensemble methods, trained approaches, feature extraction, or special<lb/> handling of corpus characteristics.<lb/></p>

			<p>Against this background, our achieved detection performance is comparably outstanding, given the specialized<lb/> requirements in terms of scalability as well as the focus on a high-precision identification.<lb/></p>

			<p>Dataset properties. Table <ref type="table">5</ref> lists the distribution of identified cases and original publications across scientific<lb/> disciplines. The relative share of disciplines is approximately the same for both, with only natural sciences having a<lb/> decreased share in cases compared to publications. Figure <ref type="figure">3</ref> shows cumulative ratios of cases per normalized length,<lb/> i.e., matched case length divided by total publication length, and normalized position, i.e., start offset divided by total<lb/> publication length. Less than one percent of cases encompasses more than 20% of the original publication. 90% of<lb/> cases cover at most 1% of the original publication. Some duplicate publications were contained in the dataset under<lb/> different DOIs, as made evident by the small spike at normalized length larger than 0.99. Most of the reuse cases occur<lb/> in the last 5% of a publication. This is likely due to author contribution statements, copyright notices, or acknowl-<lb/>edgements contributing a majority of boilerplate text reuse. The distribution over the rest of the relative positions is<lb/> approximately uniform. Overall, these three key properties highlight the validity of the data, and, combined with the<lb/> overall amount of cases, this allows to build focused subsets of substantial size for downstream tasks and analysis.<lb/></p>

			<head>Usage Notes<lb/></head>

			<p>Applications and examples. Based on the various reuse cases contained in Webis-STEREO-21, a<lb/> variety of research questions can be answered. These include the study of discipline-specific writing practices,<lb/> comparative studies, and a variety of machine learning tasks. The corpus includes a wide range of reuse cases,<lb/> and the operationalization of text reuse is deliberately chosen to encompass many phenomena of reuse. Webis-<lb/>STEREO-21 contains mainly &quot;innocent&quot; instances of reuse, such as short phrases reused by the same authors,<lb/> standardized technical language, wording prescribed by publishers (e.g., licenses), or established wording of<lb/> recurring blocks of text (e.g., author contributions). In particular, the corpus is not a collection of plagiarism<lb/> cases, and we refrain from judging the legitimacy of the cases.<lb/></p>

			<figure type="table">PAN13 Evaluation Corpus<lb/> Precision<lb/> Recall<lb/> F0.5<lb/> No Obfuscation<lb/> 0.88<lb/> 0.90<lb/> 0.88<lb/> No Plagiarism<lb/> 1.00<lb/> 1.00<lb/> 1.00<lb/> Random Obfuscation<lb/> 0.90<lb/> 0.11<lb/> 0.37<lb/> Summary Obfuscation<lb/> 0.99<lb/> 0.10<lb/> 0.36<lb/> Translation Obfuscation<lb/> 0.88<lb/> 0.16<lb/> 0.46<lb/> Entire Corpus<lb/> 0.93<lb/> 0.46<lb/> 0.77<lb/> Table 4. Precision, Recall, and F 0.5 of the text alignment component per obfuscation strategy and on the<lb/> complete evaluation corpus.<lb/> Discipline<lb/> Cases<lb/> Publications<lb/> Natural Sciences<lb/> 21,504,070<lb/> (24%) 1,606,599 (38%)<lb/> Engineering Sciences<lb/> 14,753,613<lb/> (16%) 911,226<lb/> (21%)<lb/> Life Sciences<lb/> 43,358,077<lb/> (47%) 1,646,843 (39%)<lb/> Humanities &amp; Social Sciences 15,265,777<lb/> (17%) 748,298<lb/> (18%)<lb/> Total<lb/> 91,466,374<lb/> 4,267,166<lb/> Table 5. Number and ratio of cases and publications per scientific discipline. Percentages can exceed 100 in<lb/> sum due to multiple membership.<lb/> 0.0<lb/> 0 .2<lb/> 0.4<lb/> 0 .6<lb/> 0.8<lb/> 1 .0<lb/> Normalized Position<lb/> 10 2<lb/> 10 1<lb/> 10 0<lb/> Cumulative Ratio<lb/> (b)<lb/> 0.0<lb/> 0 .2<lb/> 0.4<lb/> 0 .6<lb/> 0.8<lb/> 1 .0<lb/> Normalized Length<lb/> 10 2<lb/> 10 1<lb/></figure>

			<figure>10 0<lb/> Cumulative Ratio<lb/> (a)<lb/> Fig. 3 (a) cumulative ratio of reuse cases by normalized case length. (b) cumulative ratio of reuse cases by<lb/> normalized position.<lb/></figure>

			<p>To illustrate the variety of reuse cases, Table <ref type="table">6</ref> shows three examples, each representing a different type of<lb/> legitimate reuse. The first is a quotation, where two authors each quote verbatim from a tertiary source. The sec-<lb/>ond is an example of a paraphrase and comes from two different articles by the same author on the same topic.<lb/> The third is an example of reuse of boilerplate text, as both are contribution statements whose structure is highly<lb/> formalized, the difference being the different contributions of the various authors. Because of the many types of<lb/> reuse, answering a particular research question may require filtering techniques to create a subset suitable for the<lb/> application at hand. The metadata included allows for fine-grained filtering, e.g., by location in the text, extent,<lb/> time, and specific scientific fields.<lb/></p>

			<head>Data accessibility.</head>

			<p>The dataset is distributed as JSONL files of reuse case metadata to enable efficient stream-<lb/>ing and filtering even with low computational resources. Since some analyses require the text of the reuse cases<lb/> Webis-STEREO-21, researchers can hydrate the corpus using the text preprocessing component of our pro-<lb/>cessing pipeline, which is included with the dataset as a standalone Python script. This enables the conversion of<lb/> GROBID extraction results, e.g. from the CORE repository, into a compatible text format so that the locators con-<lb/>tained in the dataset can be used to recover the text portions of individual reuse cases. Since the publications the<lb/> corpus is based upon are open access, the original PDF files can be easily retrieved by their DOI, further lowering<lb/> the barrier of access. We also provide the code used to compute the corpus statistics in this article to give others<lb/> interested in working with the data an example of use.<lb/> ethical considerations. Our dataset includes contemporary scientific texts (&quot;papers&quot;) with the goal of<lb/> examining the occurrence, nature, and types of text reuse that result from scientific writing practices. Given<lb/> general ethical considerations for datasets <ref type="biblio">35</ref> , three are particularly relevant to the proposed collection: (1) privacy<lb/> of the individuals included in the data, (2) effects of biases on downstream use, and (3) dataset usage for dubious<lb/> purposes. We therefore took into account a consensus on best-practices for ethical dataset creation <ref type="biblio">36-38</ref> .<lb/></p>

			<p>Ad <ref type="biblio">(1)</ref>. While the corpus does not contain author names or identifiers, all included papers are freely accessi-<lb/>ble, so it is possible to determine the identity of individual authors by referring to the original CORE/OAG data<lb/> or simply by accessing a DOI. However, we do not consider this to be problematic, since all those who participate<lb/> professionally in scientific discourse agree, by publishing their contributions, that they will go down in the scien-<lb/>tific annals under their name and that they can be examined by anyone. This is especially true for articles under<lb/> an open access license, where consent to create derivative works, public archiving, and exploitation is implied.<lb/></p>

			<p>Ad <ref type="biblio">(2)</ref>. Two types of bias can arise from our process of dataset curation. First, by using only open access pub-<lb/>lications, the types, disciplines, and characteristics of the papers included may not be representative of science<lb/> as a whole. Since it is not yet possible to analyze all scientific papers ever published, we try to minimize this risk<lb/> by using as large a sample as possible. Second, the operationalization and implementation of text reuse may vary<lb/> for more specific research questions on this topic. Our goal was therefore to employ a very general and inclusive<lb/> detection approach. For downstream tasks, some of the cases included are not interesting, and the data can fil-<lb/>tered to obtain a more targeted collection. Moreover, by reproducibly documenting its creation process, we aim<lb/> to maximize its extensibility in the future.<lb/></p>

			<p>Ad <ref type="biblio">(3)</ref>. We estimate the potential for misuse of the dataset to be low. One contentious issue is the use of the<lb/> dataset to broadly target academics on their writing practices. However, this has not been done with previously<lb/> published text reuse datasets. The novelty of this dataset compared to previous datasets is the scope, from which<lb/> no new doubtful use cases emerge. Furthermore, the dataset explicitly refrains from classifying the legitimacy of<lb/> reuse cases. Both the operationalization of the term and its intended use are intended to examine all types and<lb/> techniques of reuse of text in science, not plagiarism in particular.<lb/></p>

			<figure type="table">Publication A<lb/> Publication B<lb/> […] children than men in lower classes nor experienced the same downward<lb/> mobility. Clark writes, &quot;Thus we may speculate that England&apos;s advantage lay<lb/> in the rapid cultural, and potentially also genetic, diffusion of the values of<lb/> the economically successful throughout society in the years 1200-1800&quot;<lb/> (p. 271). It does not serve the book well to dwell on the rebuttal of its evolutionary<lb/> […] https://doi.org/10.1111/j.1475-4991.2009.00354.x<lb/> […] Impact on the standard of living, but eventually they led to the end of the<lb/> long Malthusian era. &quot;Thus we may speculate that England&apos;s advantage lay in<lb/> the rapid cultural, and potentially also genetic, diffusion of the values of the<lb/> economically successful throughout society in the years 1200-1800&quot; (p. 271).<lb/> Finally, Clark considers the great divergence among today&apos;s economies. Because<lb/> […] https://doi.org/10.1111/j.1468-0289.2008.00432_10.x<lb/> […] static approximation of the ColourSinglet Model, we have seen that the<lb/> production amplitude receives contributions from two different cuts. The<lb/> first one in its static limit gives the colour-singlet mechanism. The second<lb/> one has not been considered so far. We treat it in a gauge-invariant manner<lb/> by introducing necessary new 4-point vertices, suggestive of the colour-<lb/>octet mechanism. This new contribution can be as large as the colour-singlet<lb/> mechanism at high https://doi.org/10.1063/1.2122163<lb/> […] and we show that the lowest-order mechanism for heavy-quarkonium<lb/> production receives in general contributions from two different cuts. The<lb/> first one corresponds to the usual colour-singlet mechanism. The second one<lb/> has not been considered so far. We treat it in a gauge-invariant manner, and<lb/> introduce new 4-point vertices, suggestive of the colour-octet mechanism.<lb/> These new objects enable us to go beyond the static approximation. We show that<lb/> the contribution of […] https://doi.org/10.1016/j.physletb.2005.11.073<lb/> […] The authors declare that they have no competing interests. MS and MMD<lb/> drafted and wrote the manuscript. MS, MMD and KCRP participated in the<lb/> care of the patient and interpretation of the investigations. All authors read and<lb/> approved the final manuscript. […] https://doi.org/10.1186/1757-1626-2-147<lb/> […] The authors declare that they have no competing interests. Authors&apos;<lb/> contributions: AJB is the chief investigator of the CASP trial, he is responsible<lb/> for the conduct of the study and the clinical supervision and training of the<lb/> therapists and he wrote the first draft of this paper. CS drafted an earlier version<lb/> of the grant proposal and collaborated with AJB, MT, RR &amp; PH to produce<lb/> the successful proposal. CS also provided clinical supervision and therapist<lb/> training. LS edited and revised the proposal and is responsible for the day to<lb/> day running of the trial. All authors read and approved the final manuscript.<lb/> […] https://doi.org/10.1186/1471-244X-13-199<lb/> Table 6. Matched text with before and after context for selected reuse examples. Portions with highest similarity<lb/> in bold. DOIs of original publications given.</figure>


	</text>
</tei>
